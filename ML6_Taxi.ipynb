{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment No. 6**"
      ],
      "metadata": {
        "id": "AXjFJzk-Q1QU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reinforcement Learning:\n",
        "\n",
        "Solve the Taxi problem using reinforcement learning where the agent acts as a taxi driver to pick up a passenger at one location and then drop the passenger off at their destination."
      ],
      "metadata": {
        "id": "gzYLWeZmQ1IB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RD92dwiJQ7l",
        "outputId": "a8dbd292-6a67-4e07-d976-9c397f4cf8cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 40.88\n",
            "Average penalties per episode: 0.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "\n",
        "# Create the Taxi environment\n",
        "env = gym.make(\"Taxi-v3\")\n",
        "\n",
        "# Initialize Q-table (500 states, 6 possible actions)\n",
        "q_table = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "\n",
        "# Hyperparameters\n",
        "alpha = 0.1 # Learning rate\n",
        "gamma = 0.6 # Discount factor\n",
        "epsilon = 0.1 # Exploration-exploitation tradeoff\n",
        "episodes = 10000 # Number of episodes for training\n",
        "truncated = 0\n",
        "new_step_api=True\n",
        "\n",
        "# Training the agent using Q-learning\n",
        "for episode in range(episodes):\n",
        "  # Reset the environment and capture the state\n",
        "  state = env.reset() if isinstance(env.reset(), int) else env.reset()[0]\n",
        "  done = False\n",
        "\n",
        "  while not done:\n",
        "    # Exploration-exploitation tradeoff\n",
        "    if random.uniform(0, 1) < epsilon:\n",
        "      action = env.action_space.sample() # Explore action space\n",
        "    else:\n",
        "      action = np.argmax(q_table[state]) # Exploit learned values\n",
        "\n",
        "    # Take action and observe outcome\n",
        "    result = env.step(action)\n",
        "    if len(result) == 4: # For older gym versions\n",
        "      next_state, reward, done, info = result\n",
        "    else: # For newer gym versions (with 'truncated')\n",
        "      next_state, reward, done, truncated, info = result\n",
        "    done = done or truncated # End the episode if either is True\n",
        "\n",
        "    # Update Q-value using the Q-learning formula\n",
        "    old_value = q_table[state, action]\n",
        "    next_max = np.max(q_table[next_state])\n",
        "    # Q-learning update formula\n",
        "    q_table[state, action] = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
        "    # Transition to the next state\n",
        "    state = next_state\n",
        "\n",
        "# Testing the trained agent\n",
        "total_epochs, total_penalties = 0, 0\n",
        "episodes_test = 100\n",
        "\n",
        "for _ in range(episodes_test):\n",
        "  state = env.reset() if isinstance(env.reset(), int) else env.reset()[0]\n",
        "  epochs, penalties, reward = 0, 0, 0\n",
        "  done = False\n",
        "\n",
        "  while not done:\n",
        "    action = np.argmax(q_table[state]) # Exploit learned values\n",
        "    result = env.step(action)\n",
        "\n",
        "    if len(result) == 4: # Handle older gym version\n",
        "      next_state, reward, done, info = result\n",
        "    else: # Handle newer gym version with truncated flag\n",
        "      next_state, reward, done, truncated, info = result\n",
        "      done = done or truncated\n",
        "    if reward == -10: # Penalty for illegal pick-up/drop-off\n",
        "      penalties += 1\n",
        "\n",
        "    epochs += 1\n",
        "    state = next_state\n",
        "\n",
        "  total_penalties += penalties\n",
        "  total_epochs += epochs\n",
        "\n",
        "print(f\"Results after {episodes_test} episodes:\")\n",
        "print(f\"Average timesteps per episode: {total_epochs / episodes_test}\")\n",
        "print(f\"Average penalties per episode: {total_penalties / episodes_test}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofanZANuJQ7w"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
